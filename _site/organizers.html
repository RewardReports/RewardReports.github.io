<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <title>Reward Reports for Reinforcement Learning</title>
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/2.1.0/jquery.min.js"></script>
  <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/css/bootstrap.min.css" integrity="sha384-Vkoo8x4CGsO3+Hhxv8T/Q5PaXtkKtu6ug5TOeNV6gBiFeWPGFN9MuhOf23Q9Ifjh" crossorigin="anonymous">
  <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.min.js" integrity="sha384-wfSDF2E50Y2D1uUdj0O3uMBJnjuUD4Ih7YwaYd1iqfktj0Uod8GCExl3Og8ifwB6" crossorigin="anonymous"></script>
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link href="assets/css/base.css" rel="stylesheet">
  <link href="assets/css/style.css" rel="stylesheet">
</head>

<nav class="navbar navbar-expand-lg navbar-light bg-light" id="navbar">

  <div class="container" id="header">

    <div>
      <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-main" aria-controls="navbar-main" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
      </button>
    </div> <!-- navbar-header -->

    <div class="collapse navbar-collapse" id="navbar-main">
      <ul class="navbar-nav mx-auto">
        <li class="nav-link"><a href="/">Home</a></li>
        <li class="nav-link"><a href="/speakers.html">Speakers</a></li>
        <li class="nav-link"><a href="/schedule.html">Schedule</a></li>
        <li class="nav-link"><a href="/papers.html">Accepted Papers</a></li>
        <li class="nav-link"><a href="/organizers.html">Organizers</a></li>
        <li class="nav-link"><a href="/related-workshops.html">Related Workshops</a></li>
      </ul>

    </div> <!-- navbar-main -->

  </div> 

</nav> <!-- navbar -->

<body>

  <div class="container" id="content">

    <div class="page-content">

      <div class="row justify-content-center">
        <img src=assets/img/rewardreports2.png class="img-fluid" style="max-width:50%" />
        <div class="break"></div>
        <h1 class="text-center">Reward Reports for Reinforcement Learning</h1>
        <div class="break"></div>
        <h4 class="text-center"><a href="https://rldm.org"> The Multi-disciplinary Conference on Reinforcement Learning and Decision Making
          (RLDM)</a></h4>
        <div class="break"></div>
        <h4 class="text-center">June, 2022</h4>
        <hr>

      </div> <!-- row -->

      <h1 id="workshop-organizers">Workshop Organizers</h1>

<div class="container">
    
    <div class="organizer row">
        <div class="col-md-auto text-center">
            <img src="/assets/organizer-images/gilbert.jpg" class="organizer-img" />
            <div class="break"></div>
            
            <a href="https://www.thomaskrendlgilbert.com/" target="_blank">
                Thomas Krendl Gilbert
            </a>
            
        </div>

        <div class="organizer-bio col">​Thomas Krendl Gilbert is an interdisciplinary Ph.D. candidate in Machine Ethics and Epistemology at UC Berkeley, supported by the Center for Human-Compatible AI, the Simons Institute, and the Center for Long-Term Cybersecurity. His interest in the societal implications of RL systems grows out of his affiliation with the Simons program on the Theory of Reinforcement Learning held during fall 2020. Tom’s research examines how to ensure that the objectives for which we are optimizing in RL are aligned with normative social, political, and economic goals, and how notions of fairness, justice, equality, and rule of law can be prioritized in the design of our objectives, and objective functions. Thomas’ recent work investigates how specific algorithmic learning procedures (such as RL) reframe classical ethical questions and recall the foundations of democratic political philosophy, namely the significance of popular sovereignty and dissent for resolving normative uncertainty and modeling human preferences.
</div>
    </div>
    
    <div class="organizer row">
        <div class="col-md-auto text-center">
            <img src="/assets/organizer-images/zick.jpg" class="organizer-img" />
            <div class="break"></div>
            
            <a href="https://cyber.harvard.edu/people/tom-zick" target="_blank">
                Tom Zick
            </a>
            
        </div>

        <div class="organizer-bio col">Tom Zick earned her PhD from UC Berkeley and is currently pursuing her JD at Harvard. Her research bridges between AI ethics and law, with a focus on how to craft safe and equitable policy surrounding the adoption of AI in high-stakes domains. In the past, she has worked as a data scientist at the Berkeley Center for Law and Technology, evaluating the capacity of regulations to promote open government data. She has also collaborated with graduate students across social science and engineering to advocate for pedagogy reform focused on infusing social context into technical coursework. Outside of academia, Tom has crafted digital policy for the City of Boston as a fellow for the Mayor’s Office for New Urban Mechanics and helped early stage startups develop responsible AI frameworks. Her current research centers on the near term policy concerns surrounding reinforcement learning.
</div>
    </div>
    
    <div class="organizer row">
        <div class="col-md-auto text-center">
            <img src="/assets/organizer-images/nol.jpg" class="organizer-img" />
            <div class="break"></div>
            
            <a href="https://www.natolambert.com/" target="_blank">
                Nathan Lambert
            </a>
            
        </div>

        <div class="organizer-bio col">Nathan Lambert is  a PhD Candidate at the University of California, Berkeley working at the intersection of machine learning and robotics.  He is a member of the Department of Electrical Engineering and Computer Sciences, advised by Professor Kristofer Pister in the Berkeley Autonomous Microsystems Lab.  Nathan has worked extensively with Roberto Calandra at Facebook AI Research and is joining DeepMind Robotics remotely for the summer of 2021.  During his Ph.D., he was awarded the UC Berkeley EECS Demetri Angelakos Memorial Achievement Award for Altruism.
</div>
    </div>
    
    <div class="organizer row">
        <div class="col-md-auto text-center">
            <img src="/assets/organizer-images/sdean.jpg" class="organizer-img" />
            <div class="break"></div>
            
            <a href="https://sdean.website/" target="_blank">
                Sarah Dean
            </a>
            
        </div>

        <div class="organizer-bio col">TODO</div>
    </div>
    
</div>

<h1 id="volunteers">Volunteers</h1>

<p>We are indebted to our 2021 workshop volunteers!</p>

<div class="container">
    
    <div class="organizer row">
        <div class="col-md-auto text-center">
            <img src="/assets/volunteer-images/morgan.jpg" class="organizer-img" />
            <div class="break"></div>
            
            <a href="https://cdt-art-ai.ac.uk/students/deborah-morgan/" target="_blank">
                Deborah Morgan
            </a>
            
        </div>

        <div class="organizer-bio col">Deborah Morgan is a PhD student within the Centre for Accountable, Responsible and Transparent AI in the Department of Computer Science at the University of Bath, UK. She holds an LLB Law degree and previously practiced law as a corporate projects lawyer in the UK. She has also worked within industry as a communications consultant and in education. She holds an MSt in Education from the University of Cambridge where her research explored feedback methods within narrative writing. Her current PhD research explores the legal and societal challenges of regulating AI systems, in particular the use of experimental legal methods and regulatory sandboxes.
</div>
    </div>
    
    <div class="organizer row">
        <div class="col-md-auto text-center">
            <img src="/assets/volunteer-images/elias.png" class="organizer-img" />
            <div class="break"></div>
            
            <a href="http://blakeelias.name/" target="_blank">
                Blake Elias
            </a>
            
        </div>

        <div class="organizer-bio col">Blake Elias is a researcher at the New England Complex Systems Institute, working under Yaneer Bar-Yam. His current research applies game theory and control theory to inform optimal pandemic response. His broader interests include the application of AI to problems of coordination, governance and public policy. Previously, he was an AI Resident at Microsoft Research working on neural-symbolic computation and human-AI collaboration. Before this, he completed his SB and MEng degrees at MIT in Electrical Engineering and Computer Science, where he worked in the Media Lab and Synthetic Biology Center.
</div>
    </div>
    
</div>

<h1 id="reviewers">Reviewers</h1>

<p>In addition to the workshop organizers, our workshop reviewer comittee includes the following members:
<a target="blank" href="https://researchers.uq.edu.au/researcher/24776">Archie Chapman</a>, 
<a target="blank" href="https://simons.berkeley.edu/people/daniela-cialfi">Daniela Cialfi</a>, 
<a target="blank" href="https://people.eecs.berkeley.edu/~sarahdean/">Sarah Dean</a>,
<a target="blank" href="http://tttor.github.io/">Vektor Dewanto</a>, 
<a target="blank" href="https://www.admscentre.org.au/henry-fraser/">Henry Fraser</a>, 
<a target="blank" href="https://au.linkedin.com/in/camerondgordon">Cameron Gordon</a>, 
<a target="blank" href="https://www.linkedin.com/in/xiaoguo-neuhkuuq">Xiao Guo</a>, 
<a target="blank" href="https://www.natolambert.com/">Nathan Lambert</a>, and
<a target="blank" href="https://research.qut.edu.au/adms/people/abdul-obeid/">Abdul Obeid</a>.</p>


    </div> <!-- container -->

  </div> <!-- page-content -->

  <nav class="navbar fixed-bottom navbar-light bg-light d-flex justify-content-center">
    <a class="navbar-brand" href="mailto:perls.organizers@gmail.com">Contact Organizers</a>
  </nav>

</body>
</html>
