<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <title>Reward Reports for Reinforcement Learning</title>
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/2.1.0/jquery.min.js"></script>
  <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/css/bootstrap.min.css" integrity="sha384-Vkoo8x4CGsO3+Hhxv8T/Q5PaXtkKtu6ug5TOeNV6gBiFeWPGFN9MuhOf23Q9Ifjh" crossorigin="anonymous">
  <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.min.js" integrity="sha384-wfSDF2E50Y2D1uUdj0O3uMBJnjuUD4Ih7YwaYd1iqfktj0Uod8GCExl3Og8ifwB6" crossorigin="anonymous"></script>
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link href="assets/css/base.css" rel="stylesheet">
  <link href="assets/css/style.css" rel="stylesheet">

  <link rel="shortcut icon" type="image/png" href="/assets/img/rewardreports2.png">
  <link rel="shortcut icon" sizes="192x192" href="/assets/img/rewardreports2.png">
  <link rel="apple-touch-icon" href="/assets/img/rewardreports2.png">
</head>

<nav class="navbar navbar-expand-lg navbar-light bg-light" id="navbar">

  <div class="container" id="header">

    <div>
      <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-main" aria-controls="navbar-main" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
      </button>
    </div> <!-- navbar-header -->

    <div class="collapse navbar-collapse" id="navbar-main">
      <ul class="navbar-nav mx-auto">
        <li class="nav-link"><a href="/">Home</a></li>
        <!-- <li class="nav-link"><a href="/speakers.html">Speakers</a></li> -->
        <li class="nav-link"><a href="/workshop.html">Workshop</a></li>
        <li class="nav-link"><a href="https://github.com/RewardReports/reward-reports">R.R. Template</a></li>
        <!-- <li class="nav-link"><a href="/papers.html">Accepted Papers</a></li> -->
        <li class="nav-link"><a href="/designers.html">Designers</a></li>
        <li class="nav-link"><a href="/related-work.html">Related Work</a></li>
      </ul>

    </div> <!-- navbar-main -->

  </div> 

</nav> <!-- navbar -->

<body>

  <div class="container" id="content">

    <div class="page-content">

      <div class="row justify-content-center">
        <img src=assets/img/rewardreports2.png class="img-fluid" style="max-width:300px" />
        <div class="break"></div>
        <h1 class="text-center">Reward Reports for Reinforcement Learning</h1>
        <div class="break"></div>
        <h3 class="text-center"><em>Towards Documentation and Understanding of Dynamic Machine Learning Systems</em></h3>
        <div class="break"></div>
        <h4 class="text-center"> <strong> <span class="important">Join us at our workshop </span>on Building Accountable and Transparent RL</strong>, at the <a href="https://rldm.org"> The Multi-disciplinary Conference on Reinforcement Learning and Decision Making
          (RLDM)</a> June 11th, 2022</h4>
        <div class="break"></div>
        <h4 class="text-center"> To learn more about Reward Reports, see the 
          <a href="/assets/reward_reports_for_rl.pdf"> Reward Reports paper</a>, the
          <a href="http://arxiv.org/abs/2202.05716"> CLTC RL Risks Whitepaper</a> , or the 
          <a href="https://github.com/RewardReports/reward-reports">github repo</a> with a template.
        </h4>
        <!-- <h4 class="text-center"></h4> -->
        <hr>

      </div> <!-- row -->

      <h1 id="workshop-organizers">Workshop Organizers</h1>

<div class="container">
    
    <div class="organizer row">
        <div class="col-md-auto text-center">
            <img src="/assets/organizer-images/gilbert.jpg" class="organizer-img" />
            <div class="break"></div>
            
            <a href="https://www.thomaskrendlgilbert.com/" target="_blank">
                Thomas Krendl Gilbert
            </a>
            
        </div>

        <div class="organizer-bio col">​Thomas Krendl Gilbert is an interdisciplinary Ph.D. candidate in Machine Ethics and Epistemology at UC Berkeley, supported by the Center for Human-Compatible AI, the Simons Institute, and the Center for Long-Term Cybersecurity. His interest in the societal implications of RL systems grows out of his affiliation with the Simons program on the Theory of Reinforcement Learning held during fall 2020. Tom’s research examines how to ensure that the objectives for which we are optimizing in RL are aligned with normative social, political, and economic goals, and how notions of fairness, justice, equality, and rule of law can be prioritized in the design of our objectives, and objective functions. Thomas’ recent work investigates how specific algorithmic learning procedures (such as RL) reframe classical ethical questions and recall the foundations of democratic political philosophy, namely the significance of popular sovereignty and dissent for resolving normative uncertainty and modeling human preferences.
</div>
    </div>
    
    <div class="organizer row">
        <div class="col-md-auto text-center">
            <img src="/assets/organizer-images/zick.jpg" class="organizer-img" />
            <div class="break"></div>
            
            <a href="https://cyber.harvard.edu/people/tom-zick" target="_blank">
                Tom Zick
            </a>
            
        </div>

        <div class="organizer-bio col">Tom Zick earned her PhD from UC Berkeley and is currently pursuing her JD at Harvard. Her research bridges between AI ethics and law, with a focus on how to craft safe and equitable policy surrounding the adoption of AI in high-stakes domains. In the past, she has worked as a data scientist at the Berkeley Center for Law and Technology, evaluating the capacity of regulations to promote open government data. She has also collaborated with graduate students across social science and engineering to advocate for pedagogy reform focused on infusing social context into technical coursework. Outside of academia, Tom has crafted digital policy for the City of Boston as a fellow for the Mayor’s Office for New Urban Mechanics and helped early stage startups develop responsible AI frameworks. Her current research centers on the near term policy concerns surrounding reinforcement learning.
</div>
    </div>
    
    <div class="organizer row">
        <div class="col-md-auto text-center">
            <img src="/assets/organizer-images/lambert.jpeg" class="organizer-img" />
            <div class="break"></div>
            
            <a href="https://www.natolambert.com/" target="_blank">
                Nathan Lambert
            </a>
            
        </div>

        <div class="organizer-bio col">Nathan Lambert is  a PhD Candidate at the University of California, Berkeley working at the intersection of machine learning and robotics.  He is a member of the Department of Electrical Engineering and Computer Sciences, advised by Professor Kristofer Pister in the Berkeley Autonomous Microsystems Lab.  Nathan has worked extensively with Roberto Calandra at Facebook AI Research and is joining DeepMind Robotics remotely for the summer of 2021.  During his Ph.D., he was awarded the UC Berkeley EECS Demetri Angelakos Memorial Achievement Award for Altruism.
</div>
    </div>
    
    <div class="organizer row">
        <div class="col-md-auto text-center">
            <img src="/assets/organizer-images/dean.jpeg" class="organizer-img" />
            <div class="break"></div>
            
            <a href="https://sdean.website/" target="_blank">
                Sarah Dean
            </a>
            
        </div>

        <div class="organizer-bio col">Sarah Dean is an Assistant Professor in the Computer Science Department at Cornell.  She recently completed a PhD in EECS from UC Berkeley and was a postdoc at the University of Washington.  Sarah is interested in the interplay between optimization, machine learning, and dynamics, and her research focuses on understanding the fundamentals of data-driven control and decision-making.
</div>
    </div>
    
</div>

<h1 id="contributors">Contributors</h1>

<p>Other contributors to the reward reports line of work include.</p>

<div class="container">
    
    <div class="organizer row">
        <div class="col-md-auto text-center">
            <img src="/assets/organizer-images/snoswell.jpg" class="organizer-img" />
            <div class="break"></div>
            
            <a href="https://aaronsnoswell.github.io/" target="_blank">
                Aaron Snoswell
            </a>
            
        </div>

        <div class="organizer-bio col">TODO</div>
    </div>
    
</div>

<!-- 

# Reviewers

In addition to the workshop organizers, our workshop reviewer comittee includes the following members:
<a target="blank" href="https://researchers.uq.edu.au/researcher/24776">Archie Chapman</a>, 
<a target="blank" href="https://simons.berkeley.edu/people/daniela-cialfi">Daniela Cialfi</a>, 
<a target="blank" href="https://people.eecs.berkeley.edu/~sarahdean/">Sarah Dean</a>,
<a target="blank" href="http://tttor.github.io/">Vektor Dewanto</a>, 
<a target="blank" href="https://www.admscentre.org.au/henry-fraser/">Henry Fraser</a>, 
<a target="blank" href="https://au.linkedin.com/in/camerondgordon">Cameron Gordon</a>, 
<a target="blank" href="https://www.linkedin.com/in/xiaoguo-neuhkuuq">Xiao Guo</a>, 
<a target="blank" href="https://www.natolambert.com/">Nathan Lambert</a>, and
<a target="blank" href="https://research.qut.edu.au/adms/people/abdul-obeid/">Abdul Obeid</a>. 

-->


    </div> <!-- container -->

  </div> <!-- page-content -->

  <nav class="navbar fixed-bottom navbar-light bg-light d-flex justify-content-center">
    <a class="navbar-brand" href="mailto:geese-org@lists.berkeley.edu">Contact Organizers</a>
  </nav>

</body>
</html>
