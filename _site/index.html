<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <title>Reward Reports for Reinforcement Learning</title>
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/2.1.0/jquery.min.js"></script>
  <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/css/bootstrap.min.css" integrity="sha384-Vkoo8x4CGsO3+Hhxv8T/Q5PaXtkKtu6ug5TOeNV6gBiFeWPGFN9MuhOf23Q9Ifjh" crossorigin="anonymous">
  <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.min.js" integrity="sha384-wfSDF2E50Y2D1uUdj0O3uMBJnjuUD4Ih7YwaYd1iqfktj0Uod8GCExl3Og8ifwB6" crossorigin="anonymous"></script>
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link href="assets/css/base.css" rel="stylesheet">
  <link href="assets/css/style.css" rel="stylesheet">

  <link rel="shortcut icon" type="image/png" href="/assets/img/rewardreports2.png">
  <link rel="shortcut icon" sizes="192x192" href="/assets/img/rewardreports2.png">
  <link rel="apple-touch-icon" href="/assets/img/rewardreports2.png">
</head>

<nav class="navbar navbar-expand-lg navbar-light bg-light" id="navbar">

  <div class="container" id="header">

    <div>
      <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-main" aria-controls="navbar-main" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
      </button>
    </div> <!-- navbar-header -->

    <div class="collapse navbar-collapse" id="navbar-main">
      <ul class="navbar-nav mx-auto">
        <li class="nav-link"><a href="/">Home</a></li>
        <!-- <li class="nav-link"><a href="/speakers.html">Speakers</a></li> -->
        <li class="nav-link"><a href="/workshop.html">Workshop</a></li>
        <li class="nav-link"><a href="https://github.com/RewardReports/reward-reports">R.R. Template</a></li>
        <!-- <li class="nav-link"><a href="/papers.html">Accepted Papers</a></li> -->
        <li class="nav-link"><a href="/designers.html">Designers</a></li>
        <li class="nav-link"><a href="/related-work.html">Related Work</a></li>
      </ul>

    </div> <!-- navbar-main -->

  </div> 

</nav> <!-- navbar -->

<body>

  <div class="container" id="content">

    <div class="page-content">

      <div class="row justify-content-center">
        <img src=assets/img/rewardreports2.png class="img-fluid" style="max-width:300px" />
        <div class="break"></div>
        <h1 class="text-center">Reward Reports for Reinforcement Learning</h1>
        <div class="break"></div>
        <h3 class="text-center"><em>Towards Documentation and Understanding of Dynamic Machine Learning Systems</em></h3>
        <div class="break"></div>
        <h4 class="text-center"> <strong> <span class="important">Join us at our workshop </span>on Building Accountable and Transparent RL</strong>, at the <a href="https://rldm.org"> The Multi-disciplinary Conference on Reinforcement Learning and Decision Making
          (RLDM)</a> June 11th, 2022</h4>
        <div class="break"></div>
        <h4 class="text-center"> To learn more about Reward Reports, see the 
          <a href="/assets/reward_reports_for_rl.pdf"> Reward Reports paper</a>, the
          <a href="http://arxiv.org/abs/2202.05716"> CLTC RL Risks Whitepaper</a> , or the 
          <a href="https://github.com/RewardReports/reward-reports">github repo</a> with a template.
        </h4>
        <!-- <h4 class="text-center"></h4> -->
        <hr>

      </div> <!-- row -->

      <!-- <span class="click-to-join">[>> Click here to join the workshop live-stream <<](https://neurips.cc/virtual/2021/workshop/21864)</span> -->

<!-- <span class="click-to-join-sub">(must be registered for NeurIPS and logged-in!)</span> -->

<h1 id="overview">Overview</h1>

<p>When RL is used in societally relevant domains, practitioners must balance contested values, while anticipating and responding to resulting downstream effects. 
This will require documenting the behavior of RL systems over time, both in relation to design choices and dynamic effects. 
In this workshop, we will survey existing approaches to AI documentation, discuss the unique challenges posed by RL deployments, and introduce a proposal for “Reward Reports”: living documents that demarcate design choices and track system behavior. 
The majority of the workshop will be interactive, with participants trying out and critiquing methods of documentation for real or imagined RL applications.</p>

<p>We began addressing these issues as part of the <a href="https://simons.berkeley.edu/news/mapping-political-economy-reinforcement-learning-systems-case-autonomous-vehicles">2020 Simons Institute program on the Theory of Reinforcement Learning</a>, and throughout 2020/21 we have been broadening the discussion through an <a href="https://geesegraduates.org/2020/10/26/political-economy-of-reinforcement-learning/">ongoing reading group</a>, including perspectives from Law and Policy.
The aim of this workshop will be to establish a common language around the state of the art of RL across key societal domains.
From this examination, we hope to identify specific interpretive gaps that can be elaborated or filled by members of our community.
Our ultimate goal will be to map near-term societal concerns and indicate possible cross-disciplinary avenues towards addressing them.</p>

<h1 id="how-to-participate">How to participate</h1>

<p>Register for the Multi-disciplinary Conference on Reinforcement Learning and Decision Making (<a href="https://rldm.org/">RLDM</a>).
<!-- Contact the organizors  --></p>

<p>Send us a message with any questions!</p>

<iframe src="https://docs.google.com/forms/d/e/1FAIpQLSdtARZRCD80KADgF9uADxlxgZ-e5ub4es7ETM4iHXcSAJQUpg/viewform?embedded=true" width="100%" height="752" frameborder="0" marginheight="0" marginwidth="0">Loading…</iframe>


    </div> <!-- container -->

  </div> <!-- page-content -->

  <nav class="navbar fixed-bottom navbar-light bg-light d-flex justify-content-center">
    <a class="navbar-brand" href="mailto:geese-org@lists.berkeley.edu">Contact Organizers</a>
  </nav>

</body>
</html>
